{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZnRs8aVnZ7Ad"},"outputs":[],"source":["import tensorflow as tf\n","#import matplotlib as mpl\n","#import matplotlib.pyplot as plt\n","import os\n","import numpy as np\n","import PIL\n","\n","#mpl.rcParams['figure.figsize'] = (8, 8)\n","#mpl.rcParams['axes.grid'] = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVCGWEvHZ7Af","executionInfo":{"status":"ok","timestamp":1682560267455,"user_tz":-420,"elapsed":4962,"user":{"displayName":"Án Đồ","userId":"10520306343776103670"}},"outputId":"20d7c81e-637d-4d11-9aa5-8c150edef55f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n","14536120/14536120 [==============================] - 0s 0us/step\n"]}],"source":["pretrained_model = tf.keras.applications.MobileNetV2(include_top=True,\n","                                                     weights='imagenet')\n","pretrained_model.trainable = False\n","\n","# ImageNet labels\n","decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions\n","model_preprocess = tf.keras.applications.mobilenet_v2.preprocess_input"]},{"cell_type":"markdown","metadata":{"id":"Iil6T-x8Z7Ag"},"source":["# Util"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lDSzZ8jiZ7Ah"},"outputs":[],"source":["# Helper function to preprocess the image so that it can be inputted in MobileNetV2\n","def preprocess(image):\n","    image = tf.cast(image, tf.float32)\n","    image = tf.image.resize(image, [224, 224])\n","    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n","    image = image[None, ...]\n","    return image\n","\n","# Helper function to extract labels from probability vector\n","def get_imagenet_label(probs):\n","    return decode_predictions(probs, top=1)[0][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wS9oyPtHZ7Ah"},"outputs":[],"source":["def predict_img(img_path):\n","    image_raw = tf.io.read_file(img_path)\n","    image = tf.image.decode_jpeg(image_raw)\n","    height, width, channels = image.shape\n","    image = preprocess(image)\n","    # image = tf.image.resize(image, [224, 224])\n","    # image = image[None, ...]\n","    image_probs = pretrained_model.predict(image)\n","\n","    return (image, image_probs, height, width)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1lka8_jGZ7Ah"},"outputs":[],"source":["loss_object = tf.keras.losses.CategoricalCrossentropy()\n","\n","def create_adversarial_pattern(input_image, input_label):\n","    with tf.GradientTape() as tape:\n","        tape.watch(input_image)\n","        prediction = pretrained_model(input_image)\n","        loss = loss_object(input_label, prediction)\n","\n","    # Get the gradients of the loss w.r.t to the input image.\n","    gradient = tape.gradient(loss, input_image)\n","    # Get the sign of the gradients to create the perturbation\n","    signed_grad = tf.sign(gradient)\n","    return signed_grad"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiALimCzZ7Ai"},"outputs":[],"source":["def get_pertubation(img, prob):\n","    # Get the input label of the image.\n","    labrador_retriever_index = 208\n","    label = tf.one_hot(labrador_retriever_index, prob.shape[-1])\n","    label = tf.reshape(label, (1, prob.shape[-1]))\n","\n","    perturbations = create_adversarial_pattern(img, label)\n","    # plt.imshow(perturbations[0] * 0.5 + 0.5);  # To change [-1, 1] to [0,1]\n","    return perturbations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcSTT5eNZ7Ai"},"outputs":[],"source":["def tensor_to_image(tensor, height, width):\n","    tensor = tf.image.resize(\n","        tensor,\n","        [height, width]\n","    )\n","\n","    tensor = tensor*255\n","    tensor = np.array(tensor, dtype=np.uint8)\n","    if np.ndim(tensor)>3:\n","        assert tensor.shape[0] == 1\n","        tensor = tensor[0]\n","    return PIL.Image.fromarray(tensor)"]},{"cell_type":"markdown","metadata":{"id":"6OUv_ie9Z7Aj"},"source":["# Create Mask folder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":166},"id":"sekXYUj8Z7Aj","executionInfo":{"status":"error","timestamp":1682560863747,"user_tz":-420,"elapsed":695,"user":{"displayName":"Án Đồ","userId":"10520306343776103670"}},"outputId":"2ade9883-c6e0-4744-a584-7339719e26e7"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-85a027da87fb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/9786043778465_2.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"]}],"source":["CLEAN_PATH = r'C:\\Users\\Admin\\Documents\\demo'\n","MASK_PATH = r'C:\\Users\\Admin\\Documents\\demo'\n","imgs = os.listdir(CLEAN_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6tBASL_1Z7Aj"},"outputs":[],"source":["epsilon = .05"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7_9B5ONZ7Ak","outputId":"5f469c72-dc54-495e-dd8d-626ec5fe9536"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]}],"source":["for img in imgs:\n","    img_path = os.path.join(CLEAN_PATH, img)\n","\n","    image, prob, he, wi = predict_img(img_path)\n","    pertubation = get_pertubation(image, prob)\n","    masked_img = image + epsilon*pertubation\n","    masked_img = tf.clip_by_value(masked_img, -1, 1)\n","    # masked_img = model_preprocess(masked_img)\n","    masked_img = tensor_to_image(masked_img[0]*0.5 + 0.5, he, wi)\n","    masked_img.save(os.path.join(MASK_PATH, img))\n","\n","    # masked_img = tf.squeeze(masked_img, axis=0)\n","    # # masked_img = tf.reverse(masked_img, axis=[-1])\n","    # masked_img = tf.cast(masked_img * 255, tf.uint8)\n","    # masked_img = tf.image.encode_jpeg(masked_img, format='rgb', quality=100)\n","    # tf.io.write_file(os.path.join(MASK_PATH, img), masked_img)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZGQMUriZ7Ak"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"9ca2561c17da07f33809ca03ba7aa600fbdf40d422ce225f1db7d8c88545dfa6"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}